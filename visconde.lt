
# Basic literate tool in python

## Introduction

This is a rough tool for literate programming, built along the lines 
of the CWEB program of [Knuth and Levy](https://cs.stanford.edu/~knuth/lp.html). 
Our syntax follows that of [Literate](https://github.com/zyedidia/Literate/). 
We only implement a subset of these programs' functionality.

More precisely, this program is a minimal "tangler/weaver" which
operates on a single input file, under the restriction that any chunk
reference, (say, `@{chunk name}`) lies on a line of its own (this
means, in particular, no comments are allowed in a line that
references a chunk, and a chunk name cannot contain line breaks).

Here is the program outline.

``` python visconde.py
@{imports}

@{global definitions}

@{parse arguments}
@{process input file}
@{output tangled sources}
@{output weaved file}
```

The line below should be updated whenever this program is changed.

``` python global definitions
banner = "This is VISCONDE version 0.1.4."
```

## Arguments


The main argument is the path to the literate source file. Arguments
are parsed as usual in most command line applications, so a typical
call to `visconde` would look like this

    python3 visconde.py [OPTIONS] INPUT_FILE
    
Where `OPTIONS` can be one or more of the following.

- `--fencedwithlanguage` first word (at the same line but) after opening fence treated as language of the code block
- `--nofencedwithlanguage` text (at same line but) after opening fence treated as chunk name
- `--manyoutputs` generate one output file per root chunk
- `--nomanyoutputs` error (and no output files) if more than one root chunk
- `--tangle` produce tangled outputs (default)
- `--notangle` do not produce tangled outputs

``` python parse arguments
parser.add_argument("file", help="literate source file")

# fencedwithlanguage ===================================================
parser.add_argument("--fencedwithlanguage", help="first word on opening fence is language; the rest is chunk name",
                    action="store_true")
parser.add_argument("--nofencedwithlanguage", help="text on opening fence is chunk name (default)",
                    action="store_true")
# manyoutputs ==========================================================
parser.add_argument("--manyoutputs", help="generate one output file per root chunk",
                    action="store_true")
parser.add_argument("--nomanyoutputs", help="generate one output file per root chunk (default)",
                    action="store_true")
# tangle ===============================================================
parser.add_argument("--tangle", help="produce tangled outputs (default)",
                    action="store_true")
parser.add_argument("--notangle", help="do not produce tangled outputs",
                    action="store_true")


args = parser.parse_args()

# input file
file = args.file

# flag (no)fencedwithlanguage
if args.fencedwithlanguage and args.nofencedwithlanguage:
    print('! error: contradictory flags (fencedwithlanguage and nofencedwithlanguage)')
    #todo abort

fenced_with_language = args.fencedwithlanguage

# flag (no)manyoutputs
if args.manyoutputs and args.nomanyoutputs:
    print('! error: contradictory flags (manyoutputs and nomanyoutputs)')
    #todo abort

many_outpus = args.manyoutputs

# flag (no)tangle
if args.tangle and args.notangle:
    print('! error: contradictory flags (tangle and notangle)')
    #todo abort

tangle = not args.notangle

```

``` python imports
import argparse
```

``` python global definitions
parser = argparse.ArgumentParser()
file = ""

fenced_with_language = False
many_outpus = False
```


## Storing chunks

Each line of the input file is either text, a fence (between text and
code), or part of a code chunk. In this first pass over the input
file, we only care about the two latter cases.

We read text lines until we reach a fence (start of a code chunk). Next we store
the chunk name and accumulate the lines of the chunk in a list `chunk_text`,
which is finally stored at the point when we reach the fence ending the chunk.

``` python process input file
print(banner) # Hi!

with open(file, 'r') as input_file:
    reading_code_chunk = False
    last_line_blank = False
    chunk_name = ''
    chunk_text = [] # list of lines

    for line_number, line in enumerate(input_file):
        @{continue if not in code chunk; set `chunk_name` and `reading_code_chunk`}
    
        @{add line to `chunk_text` or complete and store chunk}
```

Every code chunk is preceeded by a blank line (i.e., a line with only whitespace).
The first line of a code chunk begins with three or more backticks (` ``` `), 
followed by the chunk name. The last line of a code chunk contains only backticks,
(as many as there were at the chunk's first line).

``` python global definitions
fence_regexp = re.compile('```+')
```

``` python imports
import re
```

Note that if `reading_code_chunk` is `False`, then we will eventually
reach a `continue` instruction; and, hence, `` @{add line to
`chunk_text`...} `` is only reached when `reading_code_chunk == True`.

``` python continue if not in code chunk; set `chunk_name` and `reading_code_chunk`
if not reading_code_chunk:
    if line.strip() == "":
        last_line_blank = True
        continue
    elif last_line_blank:
        match_fence = fence_regexp.match(line)
        if match_fence:
            fence_length = match_fence.end()
            @{store chunk name}
            chunk_line = line_number
            chunk_text = []
            reading_code_chunk = True
        else:
            last_line_blank = False

    continue
```

The chunk name is a stripped substring of the opening fence. If blocks
do not have a language specification, then the chunk name is the
(space-stripped) substring of line which goes from the last backtick
of the fence until the end of the line; otherwise, it goes from the
first space character and goes until the end of the line (we do this
so that the fence can be followed immediately by a language
specification).

```python store chunk name
j = fence_length
if fenced_with_language:
    while line[j] == ' ':
        j += 1
    while line[j] != ' ':
        j += 1
chunk_name = line[j+1:].strip()
```

We store the code of chunk named `chunk_name` in the dictionary `chunk`.
Each dictionary entry is a list of tuples `(line_num, code)` containing 
- the line number of the first line of the chunk, and
- the code in the chunk.

``` python add line to `chunk_text` or complete and store chunk
match_fence = fence_regexp.match(line)
if match_fence and match_fence.end() == fence_length:
    if chunk_name not in chunk:
        chunk[chunk_name] = []
    chunk[chunk_name] += [(chunk_line+1, chunk_text)]
    reading_code_chunk = False
    last_line_blank = False
else:
    chunk_text += [line]
```

``` python global definitions
chunk = {}
```

## From chunks to files

When we are done reading the input file, all code chunks 
are stored somewhere in the `chunk` dictionary, and it is
time to combine them and write the output files.

If chunk `'blabla'` is not referenced by any other chunk, 
we shall create a file named `blabla` whose contents are
the lines in `chunk['blabla']`. Of course, we need to watch
out for chunk references (lines such as `@{xxx}`), which
will be replaced (recursively) by the correct content 
(i.e., `chunk['xxx']`).

The first step is to identify which chunks are to become
files---we call these *root chunks*. 

``` python output tangled sources
@{build list of `root_chunks`}

if tangle and (not many_outpus) and (len(root_chunks) > 1):
    @{error: too many root chunks}
else:
    for blk in root_chunks:
        @{write `blk` to a file}
```

``` python error: too many root chunks
print('! error: too many root chunks')
#todo: abort
```

The dictionary `used_at` stores a list of chunks which refer 
to any given chunk, e.g.: `used_at['global defintions']` is 
a list of each `chunk_name` containing `@{global definitions}` 
in its text.

``` python build list of `root_chunks`
used_at = dict()

for blk in chunk:
    if blk not in used_at:
        used_at[blk] = []
    for l,b in chunk[blk]:
        for chk in chunks_of(b):
            if chk not in used_at:
                used_at[chk] = [blk]
            else:
                used_at[chk] += [blk]


root_chunks = [blk for blk, parents in used_at.items() if len(parents) == 0]
```

We need to strip spaces surrounding chunk references, as well as
spaces surrounding the chunk name. If we write `␣` to denote a space
character, then, for each line of code which is a chunk reference (for
instance, `␣␣@{␣␣␣global␣definitions␣␣}␣␣`) we proceed as follows

1.  strip leading and trailing spaces (yields `@{␣␣␣global␣definitions␣␣}`),
2.  remove `@{` and `}` (yields `␣␣␣global␣definitions␣␣`),
3.  strip spaces again (yields `global␣defintions`).

``` python global definitions
def chunks_of(code):
    return [line.strip()[2:-1].strip() for line in code if is_chunk_line(line)]
```

We finally handle writing each root chunk to a file.
The next lines to be output are stored in a buffer. More precisely, 
`buffer[i]` is the next line we'll output. The only exception to this
occurs when `buffer[i]` is a chunk reference. In this case we replace
`buffer[i]` by the lines corresponding to the appropriate chunk.
(Actually, we do something slightly different---look at the code.)

If we find a reference to chunk `c`, but `chunk[c]` is undefined, we 
consider `chunk[c]` the reference, verbatim; we also issue a warning.


``` python write `blk` to a file
print("Writing file %s... " % blk,end='')
with open(blk, 'w') as output:
    buffer = [l for c in chunk[blk] for l in c[1]]
    i = 0
    while i < len(buffer):
        @{output tangled line}
        
print("[ DONE ]")
```

Lines are either output verbatim or (if line is a valid chunk reference)
replaced by the corresponding chunk contents.

``` python output tangled line
if is_chunk_line(buffer[i]):
    the_chunk_name = chunk_line_name(buffer[i])
    if the_chunk_name not in chunk:
        @{warn of undefined chunk}

        print(buffer[i], file=output, end='') # insert reference verbatim
        i += 1
    else:
        @{add contents of chunk to buffer}
else:
    print(buffer[i], file=output, end='')
    i += 1
```

We preserve the number of spaces before a reference, adding it as a
prefix to each line when inserting the contents of a chunk. (The way
we insert lines to buffer is wasteful because slicing `buffer` creates
a (shallow) copy of the sliced portion.)

``` python add contents of chunk to buffer
indentation = re.compile(' *').match(buffer[i]).end()
indented_lines = [x for l,c in  chunk[the_chunk_name] for x in indent_code(indentation, c)]
buffer = indented_lines + buffer[i+1:]
i = 0
```

``` python warn of undefined chunk
print("! warning: undefined chunk; reference will be kept verbatim: %s" % the_chunk_name)
```

``` python global definitions
def is_chunk_line(l):
    aux = l.strip()
    return aux and (aux[0:2] == '@{' and aux[-1] == '}')

def chunk_line_name(line):
    return line.strip()[2:-1].strip()

def indent_code(indentation, code):
    return [' '*indentation + line for line in code]
```


## Weaving, hacked

Pseudo-weaving, that's more like it. We do tiny modifications to
the source file, so that (if it was properly written) it can be
passed through markdown. They fall in three categories:

1.  Add (optional) content wrapping the weaved output.
2.  Remove chunk name from fenced line (place it in a `span` tag
    preceding the code chunk).
3.  Wrap the span above and the code in divs.

``` python output weaved file
with open(file, 'r') as input_file:
    out_filename = file + '.md'
    print("Writing file %s... " % out_filename,end='')
    with open(out_filename, 'w') as output_file:
        @{output html header}
        @{weave source}
        @{output html tail}
    print("[ DONE ]")

```

We provide a mechanism for inserting stuff before (header) and after
(tail) the weaved output.

``` python output html header
html_header = ''

print(html_header, file=output_file, end='\n')
```

``` python output html tail
html_tail = ''
print(html_tail, file=output_file, end='')
```

Weaving the source code is **mostly** echoing lines, keeping track of
whether we are in a code chunk (fenced code) or not.

``` python weave source
reading_code_chunk = False
last_line_blank = False
chunk_name = ''

for line_number, line in enumerate(input_file):
    @{print line if not in code chunk; process code chunk fence}
    @{echo code text and add closing div after closing fence}

```

When entering a code block we wrap it in a div, precede it by a
span declaring the code block, and replace the named fence by a simple
fence (no names); when leaving the fenced block we close the div tag.

```python print line if not in code chunk; process code chunk fence
if not reading_code_chunk:
    if line.strip() == "":
        print(line,file=output_file, end='')
        last_line_blank = True
        continue
    elif last_line_blank:
        match_fence = fence_regexp.match(line)
        if match_fence:
            fence_length = match_fence.end()
            @{assemble `code_chunk_header`}
            print(code_chunk_header, file=output_file)
            reading_code_chunk = True
        else:
            print(line,file=output_file, end='')
            last_line_blank = False
    else:
        print(line, file=output_file, end='')

    continue
```


```python assemble `code_chunk_header`
if fenced_with_language:
    j = fence_length
    while line[j] == ' ':
        j += 1
    chunk_lang_begin = j
    while line[j] != ' ':
        j += 1
    chunk_language = line[chunk_lang_begin:j]
    chunk_name = line[j+1:].strip()
    code_chunk_header = '<' +'div class="codeblock"><'+'span class="codeblock_name">{<'+'strong>' + chunk_name + '<'+'/strong>}<'+'/span>\n\n<'+'pre class="prettyprint language-' + chunk_language +'">'
else:
    chunk_name = line[fence_length:].strip()
    code_chunk_header = '<' +'div class="codeblock"><'+'span class="codeblock_name">{<'+'strong>' + chunk_name + '<'+'/strong>}<'+'/span>\n\n<'+'pre class="prettyprint">'
```
    
``` python echo code text and add closing div after closing fence
match_fence = fence_regexp.match(line)
if match_fence and match_fence.end() == fence_length:
    print('<'+'/p'+'re><'+'/div>', file=output_file)
    reading_code_chunk = False
    last_line_blank = False
else:
    print(line, file=output_file, end='')
```

